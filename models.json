{
  "version": "2.0",
  "last_updated": "2025-06-18T23:15:00Z",
  "model_filter": {
    "included_models": [
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4.1-nano",
      "o1",
      "o1-mini",
      "claude-opus-4-20250514",
      "claude-sonnet-4-20250514",
      "claude-3-5-sonnet-20241022",
      "claude-3-5-haiku-20241022",
      "claude-3-opus-20240229",
      "gemini-2.5-pro",
      "gemini-2.5-flash",
      "gemini-2.0-pro",
      "gemini-2.0-flash",
      "gemma-3-27b-it",
      "llama-3.3-70b-instruct",
      "llama-3.1-70b-versatile",
      "llama-3.1-8b-instant",
      "mixtral-8x7b-32768",
      "mistral-small-3.2-24b-instruct-2506",
      "mistral-large-latest",
      "mistral-medium-3",
      "mistral-small-3.1",
      "mixtral-8x22b",
      "codestral-latest"
    ],
    "model_comments": {
      "gpt-4.1": "Most advanced OpenAI model for complex document analysis and detailed data extraction",
      "gpt-4.1-mini": "Excellent for complex documents to extract datapoints and tables",
      "gpt-4.1-nano": "Perfect for small documents and simple datapoints with exact copy-paste accuracy",
      "o1": "Advanced reasoning model ideal for complex structured data extraction",
      "o1-mini": "Balanced reasoning model for moderate complexity extraction tasks",
      "claude-opus-4-20250514": "Premium Anthropic model for highest quality extraction and analysis",
      "claude-sonnet-4-20250514": "Balanced performance for most document extraction needs",
      "claude-3-5-sonnet-20241022": "Reliable choice for consistent document processing",
      "claude-3-5-haiku-20241022": "Fast and cost-effective for simple extraction tasks",
      "claude-3-opus-20240229": "High-quality extraction for complex documents",
      "gemini-2.5-pro": "Google's premium model for comprehensive document analysis",
      "gemini-2.5-flash": "Fast Google model for quick document processing",
      "gemini-2.0-pro": "Reliable Google model for structured data extraction",
      "gemini-2.0-flash": "Efficient Google model for simple extraction tasks",
      "gemma-3-27b-it": "Open-source option for basic document processing",
      "llama-3.3-70b-instruct": "Meta's large model for detailed extraction work",
      "llama-3.1-70b-versatile": "Versatile model for various document types",
      "llama-3.1-8b-instant": "Quick processing for simple extraction needs",
      "mixtral-8x7b-32768": "Large context model for processing long documents",
      "mistral-small-3.2-24b-instruct-2506": "Efficient European model for standard extraction",
      "mistral-large-latest": "Mistral's flagship model for complex extraction tasks",
      "mistral-medium-3": "Balanced Mistral model for most use cases",
      "mistral-small-3.1": "Cost-effective option for simple data extraction",
      "mixtral-8x22b": "High-capacity model for demanding extraction workflows",
      "codestral-latest": "Specialized for structured data and technical documents"
    },
    "excluded_models": [
      "gpt-4-0613",
      "gpt-4-vision-preview", 
      "text-davinci-003",
      "claude-instant-1",
      "claude-2",
      "gpt-4o-mini-realtime-preview-2024-12-17"
    ],
    "excluded_keywords": [
      "embedding",
      "whisper",
      "tts", 
      "speech",
      "audio",
      "dall-e",
      "moderation",
      "ft:",
      "fine-tune",
      "vision",
      "instruct-preview",
      "0613",
      "0314",
      "pixtral",
      "preview",
      "Preview"
    ],
    "excluded_providers": [
      "azure",
      "azure_ai", 
      "bedrock",
      "bedrock_converse",
      "deepseek",
      "xai",
      "cerebras",
      "friendliai",
      "meta_llama",
      "palm",
      "replicate",
      "openrouter",
      "ai21",
      "nlp_cloud",
      "aleph_alpha",
      "sagemaker",
      "together_ai",
      "ollama",
      "deepinfra",
      "perplexity",
      "fireworks_ai",
      "anyscale",
      "cloudflare",
      "databricks",
      "sambanova",
      "snowflake",
      "nscale",
      "featherless_ai",
      "watsonx"
    ],
    "preferred_providers": [
      "openai",
      "anthropic",
      "vertex_ai",
      "vertex_ai-language-models", 
      "mistral",
      "groq"
    ],
    "provider_mappings": {
      "openai": "openai",
      "anthropic": "anthropic",
      "vertex_ai": "google",
      "vertex_ai-language-models": "google",
      "mistral": "mistral",
      "cohere": "cohere",
      "groq": "groq",
      "together_ai": "together_ai",
      "replicate": "replicate",
      "huggingface": "huggingface",
      "azure": "azure",
      "bedrock": "bedrock",
      "ollama": "ollama",
      "palm": "google",
      "claude": "anthropic",
      "meta": "meta",
      "google": "google"
    },
    "max_input_cost_per_1k_tokens": 0.05,
    "min_max_tokens": 5000
  }
}
